#!/bin/bash
#SBATCH --array=1-30
#SBATCH --time=10:00:00
#SBATCH --mem=10gb

# Load module and initalize environment
module load conda
conda activate ../../envs

num_gen=100
num_trials=1
pop_size=100

echo "TIME START"
date

echo "Job $SLURM_JOB_ID"
echo "Number $SLURM_ARRAY_TASK_ID"

echo "Running GA for ${num_gen} generations with a population size of ${pop_size}"
echo "Running GA for ${num_trials} trials"

# Run script
ds_name="circles"
echo "Running ${ds_name} dataset"
python -u run_see_classify_circles.py --pop-size=${pop_size} --num-gen=${num_gen} --num-trials=${num_trials} --cross-val
# quick change to not redirect to file
# python run_see_classify_dhahri.py --pop-size=${pop_size} --num-gen=${num_gen} --num-trials=${num_trials} > $SLURM_JOB_ID.txt

# extract hof data
# grep "# GEN HOF_index" $SLURM_JOB_ID.txt | cut -d '|' -f2 > "${ds_name}_hof_${num_gen}_${pop_size}_${SLURM_JOB_ID}.csv"

# extract population data
# grep "# GEN population_index" $SLURM_JOB_ID.txt | cut -d '|' -f2 > "${ds_name}_population_${num_gen}_${pop_size}_${SLURM_JOB_ID}.csv"

echo "TIME END"
date

echo "FINNISHED RUNNING SCRIPT"
